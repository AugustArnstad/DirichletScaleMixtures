{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "from cmdstanpy import set_cmdstan_path\n",
    "\n",
    "from utils.model_runner import run_regression_model\n",
    "from utils.load_abalone import load_abalone_regression_data\n",
    "\n",
    "# Set CmdStan path (edit if needed)\n",
    "set_cmdstan_path(\"/Users/augustarnstad/.cmdstan/cmdstan-2.36.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name   = \"dirichlet_horseshoe\"   # e.g. \"horseshoe\", \"dirichlet_horseshoe\", ...\n",
    "overwrite    = False             \n",
    "output_dir   = \"results\"         \n",
    "standardize  = True              \n",
    "\n",
    "# Data split / seed\n",
    "frac = 0.2\n",
    "seed = 42\n",
    "\n",
    "# Model/run settings\n",
    "H = 16\n",
    "L = 1\n",
    "burnin_samples = 1000\n",
    "samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_abalone_regression_data(\n",
    "    standardized=standardize,\n",
    "    frac=frac\n",
    ")\n",
    "\n",
    "N, p = X_train.shape\n",
    "data_type = \"abalone\"\n",
    "\n",
    "config_name = f\"abalone_N{N}_p{p}\" + (\"_standardized\" if standardize else \"\")\n",
    "model_output_dir = os.path.join(output_dir, model_name, config_name)\n",
    "\n",
    "print(\"Config:\", config_name)\n",
    "print(\"Output:\", model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not overwrite) and os.path.exists(model_output_dir):\n",
    "    print(f\"[Skip] Already completed: {config_name}\")\n",
    "else:\n",
    "    print(f\"[Run] Running model on: {config_name}\")\n",
    "\n",
    "    args = SimpleNamespace(\n",
    "        N=N,\n",
    "        p=p,\n",
    "        sigma=None,\n",
    "        data=data_type,\n",
    "        standardize=standardize,\n",
    "        test_shift=None,\n",
    "        model=model_name,\n",
    "        H=H,\n",
    "        L=L,\n",
    "        config=config_name,\n",
    "        seed=seed,\n",
    "        data_config=\"realworld\",\n",
    "        model_output_dir=model_output_dir,\n",
    "        burnin_samples=burnin_samples,\n",
    "        samples=samples,\n",
    "        overwrite=overwrite, \n",
    "        output_dir=output_dir  \n",
    "    )\n",
    "\n",
    "    run_regression_model(\n",
    "        model_name=model_name,\n",
    "        config_name=config_name,\n",
    "        X_train=X_train,\n",
    "        X_test=X_test,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        args=args\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/abalone\"\n",
    "\n",
    "results_dir_tanh = \"results/regression/single_layer/tanh/abalone\"\n",
    "\n",
    "model_names_tanh = [\"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\", \"Beta Horseshoe tanh\", \"Beta Student T tanh\"]\n",
    "\n",
    "from utils.model_loader import get_model_fits\n",
    "\n",
    "full_config_path = \"abalone_N3341_p8\"\n",
    "\n",
    "tanh_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from properscoring import crps_ensemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for model_name, model_entry in tanh_fit.items():\n",
    "    post = model_entry[\"posterior\"]\n",
    "\n",
    "    y_samps = post.stan_variable(\"output_test\").squeeze(-1)\n",
    "\n",
    "    y_mean = y_samps.mean(axis=0)                                   # (n_test,)\n",
    "    rmse_post_mean = float(np.sqrt(mean_squared_error(y_test, y_mean)))\n",
    "\n",
    "    per_draw_rmse = np.sqrt(((y_samps - y_test[None, :])**2).mean(axis=1))  # (S,)\n",
    "    rmse_draw_mean = float(per_draw_rmse.mean())\n",
    "\n",
    "    crps = float(np.mean(crps_ensemble(y_test, y_samps.T)))\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE_posterior_mean\": rmse_post_mean,\n",
    "        \"RMSE_mean_over_draws\": rmse_draw_mean,\n",
    "        \"CRPS\": crps,\n",
    "        \"n_draws\": y_samps.shape[0]\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values(\"RMSE_posterior_mean\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparse_rmse_results_abalone(models, all_fits, forward_pass, frac,\n",
    "                         sparsity=0.0, prune_fn=None):\n",
    "    results = []\n",
    "    posterior_means = []\n",
    "    for model in models:\n",
    "        try:\n",
    "            fit = all_fits[model]['posterior']\n",
    "            W1_samples = fit.stan_variable(\"W_1\")           # (S, P, H)\n",
    "            W2_samples = fit.stan_variable(\"W_L\")           # (S, H, O)\n",
    "            b1_samples = fit.stan_variable(\"hidden_bias\")   # (S, O, H)\n",
    "            b2_samples = fit.stan_variable(\"output_bias\")   # (S, O)\n",
    "        except KeyError:\n",
    "            print(f\"[SKIP] Model or posterior not found:\")\n",
    "            continue\n",
    "\n",
    "        S = W1_samples.shape[0]\n",
    "        rmses = np.zeros(S)\n",
    "        #print(y_test.shape)\n",
    "        _, X_test, _, y_test = load_abalone_regression_data(standardized=False, frac=frac)\n",
    "        y_hats = np.zeros((S, y_test.shape[0]))\n",
    "\n",
    "        for i in range(S):\n",
    "            W1 = W1_samples[i]\n",
    "            W2 = W2_samples[i]\n",
    "\n",
    "            # Apply pruning mask if requested\n",
    "            if prune_fn is not None and sparsity > 0.0:\n",
    "                masks = prune_fn([W1, W2], sparsity)\n",
    "                W1 = W1 * masks[0]\n",
    "                #W2 = W2 * masks[1]\n",
    "\n",
    "            y_hat = forward_pass(X_test, W1, b1_samples[i][0], W2, b2_samples[i])\n",
    "            y_hats[i] = y_hat.squeeze()  # Store the prediction for each sample\n",
    "            rmses[i] = np.sqrt(np.mean((y_hat.squeeze() - y_test)**2))\n",
    "            \n",
    "        posterior_mean = np.mean(y_hats, axis=0)\n",
    "        posterior_mean_rmse = np.sqrt(np.mean((posterior_mean - y_test.squeeze())**2))\n",
    "\n",
    "        posterior_means.append({\n",
    "            'model': model,\n",
    "            'sparsity': sparsity,\n",
    "            'posterior_mean_rmse': posterior_mean_rmse\n",
    "        })\n",
    "\n",
    "        for i in range(S):\n",
    "            results.append({\n",
    "                'model': model,\n",
    "                'sparsity': sparsity,\n",
    "                'rmse': rmses[i]\n",
    "            })\n",
    "\n",
    "    df_rmse = pd.DataFrame(results)\n",
    "    df_posterior_rmse = pd.DataFrame(posterior_means)\n",
    "\n",
    "    return df_rmse, df_posterior_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparsity import forward_pass_tanh, local_prune_weights\n",
    "\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "df_rmse_tanh, df_posterior_rmse_tanh = {}, {}\n",
    "\n",
    "for sparsity in sparsity_levels:\n",
    "    df_rmse_tanh[sparsity], df_posterior_rmse_tanh[sparsity] = compute_sparse_rmse_results_abalone(\n",
    "        models = model_names_tanh,\n",
    "        all_fits = tanh_fit, \n",
    "        forward_pass = forward_pass_tanh,\n",
    "        frac=1.0,\n",
    "        sparsity=sparsity, \n",
    "        prune_fn=local_prune_weights\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_global_mask_from_posterior(\n",
    "    W_samples,\n",
    "    sparsity,\n",
    "    method=\"Eabs\",          # \"Eabs\" or \"Eabs_stability\"\n",
    "    stability_quantile=0.1, # used if method=\"Eabs_stability\"\n",
    "    prune_smallest=True\n",
    "):\n",
    "    \"\"\"\n",
    "    W_samples: array (S, ..., ...) posterior draws of a weight matrix.\n",
    "    sparsity: fraction to prune (q). Keeps (1-q).\n",
    "    Returns mask with same trailing shape as one draw, dtype float {0,1}.\n",
    "    \"\"\"\n",
    "    assert 0.0 <= sparsity < 1.0\n",
    "    S = W_samples.shape[0]\n",
    "    W_abs = np.abs(W_samples)  # (S, ...)\n",
    "\n",
    "    # Importance score a = E|w|\n",
    "    a = W_abs.mean(axis=0)     # (..., ...)\n",
    "\n",
    "    if method == \"Eabs\":\n",
    "        score = a\n",
    "    elif method == \"Eabs_stability\":\n",
    "        # Stability proxy pi = P(|w| > t), where t is a small global quantile of |w|\n",
    "        t = np.quantile(W_abs.reshape(S, -1), stability_quantile)\n",
    "        pi = (W_abs > t).mean(axis=0)\n",
    "        # Combine: emphasize both \"large on average\" and \"consistently non-tiny\"\n",
    "        score = a * pi\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'Eabs' or 'Eabs_stability'\")\n",
    "\n",
    "    # Decide how many to prune\n",
    "    num_params = score.size\n",
    "    k_prune = int(np.floor(sparsity * num_params))\n",
    "    if k_prune == 0:\n",
    "        return np.ones_like(score, dtype=float)\n",
    "\n",
    "    flat = score.reshape(-1)\n",
    "\n",
    "    if prune_smallest:\n",
    "        # prune lowest scores\n",
    "        thresh = np.partition(flat, k_prune - 1)[k_prune - 1]\n",
    "        mask = (score > thresh).astype(float)\n",
    "        # if ties create too many kept/pruned, fix deterministically\n",
    "        # (rare but possible with many equal scores)\n",
    "        if mask.sum() > num_params - k_prune:\n",
    "            # drop some tied-at-threshold entries\n",
    "            idx_tied = np.where(score.reshape(-1) == thresh)[0]\n",
    "            need_drop = int(mask.sum() - (num_params - k_prune))\n",
    "            if need_drop > 0:\n",
    "                mask_flat = mask.reshape(-1)\n",
    "                mask_flat[idx_tied[:need_drop]] = 0.0\n",
    "                mask = mask_flat.reshape(score.shape)\n",
    "        elif mask.sum() < num_params - k_prune:\n",
    "            # add some tied entries if we kept too few\n",
    "            idx_tied = np.where(score.reshape(-1) == thresh)[0]\n",
    "            need_add = int((num_params - k_prune) - mask.sum())\n",
    "            if need_add > 0:\n",
    "                mask_flat = mask.reshape(-1)\n",
    "                # add back from tied\n",
    "                add_candidates = idx_tied[mask_flat[idx_tied] == 0.0]\n",
    "                mask_flat[add_candidates[:need_add]] = 1.0\n",
    "                mask = mask_flat.reshape(score.shape)\n",
    "    else:\n",
    "        # prune largest (not typical)\n",
    "        thresh = np.partition(flat, num_params - k_prune)[num_params - k_prune]\n",
    "        mask = (score < thresh).astype(float)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def precompute_global_masks(\n",
    "    all_fits,\n",
    "    model,\n",
    "    sparsity_levels,\n",
    "    prune_W2=False,\n",
    "    method=\"Eabs_stability\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns dict: sparsity -> (mask_W1, mask_W2 or None)\n",
    "    \"\"\"\n",
    "    fit = all_fits[model][\"posterior\"]\n",
    "\n",
    "    W1_samples = fit.stan_variable(\"W_1\")  # (S, P, H)\n",
    "    W2_samples = fit.stan_variable(\"W_L\")  # (S, H, O) or (S, H) depending on O\n",
    "\n",
    "    masks = {}\n",
    "    for q in sparsity_levels:\n",
    "        mask_W1 = build_global_mask_from_posterior(W1_samples, q, method=method)\n",
    "        mask_W2 = None\n",
    "        if prune_W2:\n",
    "            mask_W2 = build_global_mask_from_posterior(W2_samples, q, method=method)\n",
    "        masks[q] = (mask_W1, mask_W2)\n",
    "    return masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logsumexp(a, axis=None):\n",
    "    amax = np.max(a, axis=axis, keepdims=True)\n",
    "    out = amax + np.log(np.sum(np.exp(a - amax), axis=axis, keepdims=True))\n",
    "    return np.squeeze(out, axis=axis)\n",
    "\n",
    "def gaussian_nll_pointwise(y, mu, sigma):\n",
    "    return 0.5*np.log(2*np.pi*(sigma**2)) + 0.5*((y-mu)**2)/(sigma**2)\n",
    "\n",
    "def compute_sparse_metrics_results_globalmask(\n",
    "    models, all_fits, forward_pass,\n",
    "    sparsity=0.0,\n",
    "    masks_cache=None,\n",
    "    prune_W2=False,\n",
    "    compute_nll=True,\n",
    "    noise_var_name=\"sigma\",\n",
    "    frac = 1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate on a large generated test set instead of the stored tiny X_test/y_test.\n",
    "    Assumes model was trained on standardized y if standardize_y=True.\n",
    "    \"\"\"\n",
    "    posterior_means = []\n",
    "    # Build large eval set consistent with training split standardization\n",
    "    X_train, X_test, y_train, y_test = load_abalone_regression_data(standardized=False, frac=frac)\n",
    "\n",
    "\n",
    "    for model in models:\n",
    "        try:\n",
    "            fit = all_fits[model]['posterior']\n",
    "            W1_samples = fit.stan_variable(\"W_1\")           # (S, P, H)\n",
    "            W2_samples = fit.stan_variable(\"W_L\")           # (S, H, O)\n",
    "            b1_samples = fit.stan_variable(\"hidden_bias\")   # (S, O, H)\n",
    "            b2_samples = fit.stan_variable(\"output_bias\")   # (S, O)\n",
    "\n",
    "            noise_samples = None\n",
    "            if compute_nll:\n",
    "                try:\n",
    "                    noise_samples = fit.stan_variable(noise_var_name).squeeze()\n",
    "                except Exception:\n",
    "                    noise_samples = None\n",
    "        except KeyError:\n",
    "            print(f\"[SKIP] Model or posterior not found: -> {model}\")\n",
    "            continue\n",
    "\n",
    "        S = W1_samples.shape[0]\n",
    "        y_hats = np.zeros((S, y_test.shape[0]))\n",
    "\n",
    "        mask_W1 = mask_W2 = None\n",
    "        if masks_cache is not None and sparsity > 0.0:\n",
    "            mask_W1, mask_W2 = masks_cache[(model)][sparsity]\n",
    "\n",
    "        for i in range(S):\n",
    "            W1 = W1_samples[i]\n",
    "            W2 = W2_samples[i]\n",
    "\n",
    "            if mask_W1 is not None:\n",
    "                W1 = W1 * mask_W1\n",
    "            if prune_W2 and (mask_W2 is not None):\n",
    "                W2 = W2 * mask_W2\n",
    "\n",
    "            y_hat = forward_pass(X_test, W1, b1_samples[i][0], W2, b2_samples[i]).squeeze()\n",
    "            y_hats[i] = y_hat\n",
    "\n",
    "        # posterior mean RMSE (standardized scale)\n",
    "        posterior_mean = y_hats.mean(axis=0)\n",
    "        posterior_mean_rmse = np.sqrt(np.mean((posterior_mean - y_test)**2))\n",
    "\n",
    "        out_pm = {\n",
    "            'N': X_train.shape[0],\n",
    "            'model': model,\n",
    "            'sparsity': sparsity,\n",
    "            'n_eval': y_test.shape[0],\n",
    "            'posterior_mean_rmse': posterior_mean_rmse,\n",
    "        }\n",
    "\n",
    "        if compute_nll:\n",
    "            if noise_samples is None:\n",
    "                sig_s = np.ones(S)\n",
    "            else:\n",
    "                sig_s = np.asarray(noise_samples).reshape(-1)[:S]\n",
    "\n",
    "            # Expected NLL\n",
    "            nll_draws = np.array([\n",
    "                gaussian_nll_pointwise(y_test, y_hats[i], sig_s[i]).mean()\n",
    "                for i in range(S)\n",
    "            ])\n",
    "            expected_nll = nll_draws.mean()\n",
    "\n",
    "            # Predictive (mixture) NLL\n",
    "            loglik = -np.stack([\n",
    "                gaussian_nll_pointwise(y_test, y_hats[i], sig_s[i])\n",
    "                for i in range(S)\n",
    "            ], axis=0)  # (S, n_eval)\n",
    "            lppd = (_logsumexp(loglik, axis=0) - np.log(S)).mean()\n",
    "            predictive_nll = -lppd\n",
    "\n",
    "            out_pm[\"expected_nll\"] = expected_nll\n",
    "            out_pm[\"predictive_nll\"] = predictive_nll\n",
    "\n",
    "\n",
    "        posterior_means.append(out_pm)\n",
    "\n",
    "    return pd.DataFrame(posterior_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_masks_cache_for_all(\n",
    "    all_fits,\n",
    "    models,\n",
    "    sparsity_levels,\n",
    "    prune_W2=False,\n",
    "    method=\"Eabs_stability\"\n",
    "):\n",
    "    masks_cache = {}\n",
    "    for model in models:\n",
    "        try:\n",
    "            masks_cache[(model)] = precompute_global_masks(\n",
    "                all_fits=all_fits,\n",
    "                model=model,\n",
    "                sparsity_levels=sparsity_levels,\n",
    "                prune_W2=prune_W2,\n",
    "                method=method\n",
    "            )\n",
    "        except KeyError:\n",
    "            print(f\"[SKIP MASKS] Missing fit for -> {model}\")\n",
    "    return masks_cache\n",
    "\n",
    "\n",
    "masks_tanh = build_masks_cache_for_all(tanh_fit, model_names_tanh, sparsity_levels, prune_W2=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_tanh = {}\n",
    "\n",
    "for q in sparsity_levels:\n",
    "    df_post_tanh[q] = compute_sparse_metrics_results_globalmask(\n",
    "        models=model_names_tanh,\n",
    "        all_fits=tanh_fit,\n",
    "        forward_pass=forward_pass_tanh,\n",
    "        sparsity=q,\n",
    "        masks_cache=masks_tanh,\n",
    "        prune_W2=False,\n",
    "        compute_nll=True,\n",
    "        noise_var_name=\"sigma\",\n",
    "        frac=1.0\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
